<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Machine Learning Aproach to Classify Music Based on Genre &#8211; Anand's Blog</title>
<meta name="description" content="Create a web app in Django to classify music based on genre.">
<meta name="keywords" content="pyhton, machine learning">


<!-- Twitter Cards -->
<meta name="twitter:title" content="Machine Learning Aproach to Classify Music Based on Genre">
<meta name="twitter:description" content="Create a web app in Django to classify music based on genre.">



<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://localhost:4000/images/Anand.jpg">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning Aproach to Classify Music Based on Genre">
<meta property="og:description" content="Create a web app in Django to classify music based on genre.">
<meta property="og:url" content="http://localhost:4000/blog/machine-learning-pproach-to-classify-music-based-on-genre/">
<meta property="og:site_name" content="Anand's Blog">





<link rel="canonical" href="http://localhost:4000/blog/machine-learning-pproach-to-classify-music-based-on-genre/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Anand's Blog Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<script src="https://use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
  <script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>


<!-- MathJax -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body id="post">

<div class="navigation-wrapper">
	<nav role="navigation" id="site-nav" class="animated drop">
	    <ul>
      
		    
		    <li><a href="http://localhost:4000/" >Home</a></li>
		  
		    
		    <li><a href="http://localhost:4000/portfolio/" >Portfolio</a></li>
		  
		    
		    <li><a href="http://localhost:4000/resume/" >Resume</a></li>
		  
		    
		    <li><a href="http://localhost:4000/about/" >About</a></li>
		  
	    </ul>
	</nav>
</div><!-- /.navigation-wrapper -->

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->

<header class="masthead">
	<div class="wrap">
      
  		<a href="http://localhost:4000/" class="site-logo" rel="home" title="Anand's Blog"><img src="http://localhost:4000/images/Anand.jpg" width="200" height="200" alt="Anand's Blog logo" class="animated fadeInDown"></a>
      
      <h1 class="site-title animated fadeIn"><a href="http://localhost:4000/">Anand's Blog</a></h1>
		<h2 class="site-description animated fadeIn" itemprop="description">My Experiments With Computer.</h2>
	</div>
</header><!-- /.masthead -->

<div class="js-menu-screen menu-screen"></div>


<div id="main" role="main">
  <article class="hentry">
    
    <div class="entry-wrapper">
      <header class="entry-header">
        <ul class="entry-tags">
          <li><a href="http://localhost:4000/tags/#pyhton" title="Pages tagged pyhton">pyhton</a></li><li><a href="http://localhost:4000/tags/#machine learning" title="Pages tagged machine learning">machine learning</a></li>
        </ul>
        
          <h1 class="entry-title">Machine Learning Aproach to Classify Music Based on Genre</h1>
        
      </header>
      <footer class="entry-meta">
        
        
          <img src="http://localhost:4000/images/Anand.jpg" class="bio-photo" alt="Anand Nautiyal bio photo"></a>
        
        <span class="author vcard">By <span class="fn">Anand Nautiyal</span></span>
        <span class="entry-date date published"><time datetime="2017-07-29T11:58:29+05:30"><i class="fa fa-calendar-o"></i> July 29, 2017</time></span>
        
        
        
        
      </footer>
      <div class="entry-content">
        <h1 id="music-genre-classifier">Music Genre Classifier</h1>

<p><img src="/images/img.jpg" alt="Screenshot" /></p>

<h3 id="demohttpsgenreclassifierherokuappcom"><a href="https://genreclassifier.herokuapp.com/">Demo</a></h3>

<h3 id="table-of-contents">Table of Contents</h3>

<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#requirements">Requirements</a></li>
  <li><a href="#installation">Installation</a></li>
  <li><a href="#music-genre-classifier-app">Music Genre Classifier App</a></li>
  <li><a href="#architecture">Architecture</a></li>
  <li><a href="#flow-chart">Flow Chart</a></li>
  <li><a href="#prototype">Prototype</a>
    <ul>
      <li><a href="#feature-extraction">Feature Extraction</a></li>
      <li><a href="#principal-component-analysis">Principal Component Analysis.</a></li>
      <li><a href="#dimensionality-reduction">Dimensionality reduction</a></li>
      <li><a href="#classification">Classification</a>
        <ul>
          <li><a href="#k-nearest-neighbors-knn">K-nearest neighbors (KNN)</a></li>
          <li><a href="#logistic-regression">Logistic Regression</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#python-package-mysvm">Python package mysvm</a>
    <ul>
      <li><a href="#feature"><em>feature</em></a></li>
      <li><a href="#svm"><em>svm</em></a></li>
      <li><a href="#acc"><em>acc</em></a></li>
    </ul>
  </li>
  <li><a href="#results">Results</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
  <li><a href="#license">License</a></li>
</ul>

<p>Music is categorized into subjective categories called genres. With the growth of the internet and multimedia systems applications that deal with the musical databases gained importance and demand for Music Information Retrieval (MIR) applications increased. Musical genres have no strict definitions and boundaries as they arise through a complex interaction between the public, marketing, historical, and cultural factors. This is Web Application that Classify Music in to genres.</p>

<h2 id="requirements">Requirements</h2>

<ul>
  <li>Django (1.11)</li>
  <li>Numpy (1.12.1)</li>
  <li>Scikit-Learn (0.18.1)</li>
  <li>Scipy (0.19.0)</li>
  <li>Python-Speech-Features (0.5)</li>
  <li>Pydub (0.18.0)</li>
</ul>

<h2 id="installation">Installation</h2>
<ul>
  <li><code class="highlighter-rouge">git clone https://github.com/indrajithi/mgc-django.git</code></li>
  <li><code class="highlighter-rouge">pip install -r requirements.txt</code></li>
  <li><code class="highlighter-rouge">python manage.py migrate</code></li>
  <li><code class="highlighter-rouge">python manage.py runserver</code></li>
  <li><em>App will run on</em> <code class="highlighter-rouge">localhost:8000</code></li>
</ul>

<h2 id="music-genre-classifier-app">Music Genre Classifier App</h2>
<p>Our web application is written in Python using Django framework. It uses a trained <code class="highlighter-rouge">Poly Kernel SVM</code> for finding the genre. Every HTTP request is first gone to the url dispatcher <code class="highlighter-rouge">urls.py</code> which will contain a view present in <code class="highlighter-rouge">views.py</code>. We can write rules in <code class="highlighter-rouge">views.py</code> to handle each HTTP request on that url.
    We have written views for HTTP POST and GET requests to upload music and find genre. There need to be models <code class="highlighter-rouge">(models.py)</code> for files that we store in the database. The file is automatically deleted once we find the genre. 
    Python objects can be saved in to the disk by using a module <code class="highlighter-rouge">Joblib</code> from <code class="highlighter-rouge">sklearn.externals</code>: <code class="highlighter-rouge">joblib.dump (object, filename)</code>. Our trained classifier is saved in to the disk and loaded by <code class="highlighter-rouge">joblib.load(filename)</code>. Since our training dataset is small, our classifier object does not need to be compressed. Our web application uses the package <code class="highlighter-rouge">mysvm</code> which we developed to extract features and to find the genre label.</p>

<h2 id="architecture">Architecture</h2>
<p><img src="/images/arc.png" alt="Architecture" /></p>

<h2 id="flow-chart">Flow Chart</h2>
<p><img src="/images/flowchart.png" alt="Flow Chart" /></p>

<p>The browser will send HTTP request as GET or POST from our Web App. GET request can be for loading templates which is an html file or for a static file, which includes front end JavaScript files (js), stylesheets (css), true type fonts(ttf) and image files. User upload the file by a HTTP POST. Our front end javascript will convert the given file as <strong>BLOB (binary large objects)</strong> files of size 1MB before POST. After a successful POST, user can send a GET request for finding the genre label.</p>

<p>We have developed a python package called <code class="highlighter-rouge">mysvm</code> for extracting features and classifying music. This package is added to our Web App. On receiving a GET request for genre label, we convert the file to <code class="highlighter-rouge">.wav</code> if it is in other format. Then the features are extracted from the audio file using <code class="highlighter-rouge">mysvm.feature.extract (filename)</code>. Genre labels can be found by <code class="highlighter-rouge">mysvm.svm.getGenre(filename)</code> function call. If multi option is selected by the user then <code class="highlighter-rouge">mysvm.svm.getMultiGenre(filename)</code> function is called. This will get all the probabilities of a genres which the given music belongs to. If the probability is greater than 0.15, we will push the label into the stack of maximum size 3. The labels are sent as JSON data in the response. If single genre label is selected the label which is having highest probability is sent in response.</p>

<h2 id="prototypehttpsgithubcomindrajithimusic-genre-classification-matlab"><a href="https://github.com/indrajithi/music-genre-classification-matlab">Prototype</a></h2>

<p>We need to find the best classification algorithm that can be used in our Web App. Matlab is ideal to implement machine learning algorithms in minimum lines of code. Before making the Web App in python we made a prototype in Matlab.</p>

<h3 id="feature-extraction">Feature Extraction</h3>

<p>We chose to extract MFCC from the audio files as the feature. For finding MFCC in Matlab, we have used HTK MFCC MATLAB toolkit. The output will be a matrix of 13<em>n dimensional vector. Where n depends on the total duration of the audio. 13</em>(100*sec).<br />
    While feature extraction we were getting ‘nan’(not a number) and infinity in the output. This is usually caused be a division by zero or a very small number closed to 0 resulting in infinity/nan in the output. This could be a regular result or some algorithm or implementation error in the MFCC toolkit. To overcome this situation, we have set nan or infinity entries in the feature array to 0.</p>

<h3 id="principal-component-analysis">Principal Component Analysis.</h3>

<p>Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components (or sometimes, principal modes of variation) [7]. After doing a PCA on the data we got 90% variance and should reduce the feature dimension.</p>

<figure class="highlight"><pre><code class="language-matlab" data-lang="matlab"><span class="p">[</span><span class="n">input2</span><span class="p">,</span> <span class="n">eigvec</span><span class="p">,</span> <span class="n">eigvalue</span><span class="p">]</span> <span class="o">=</span> <span class="n">pca</span> <span class="p">(</span><span class="n">ds</span><span class="o">.</span> <span class="nb">input</span><span class="p">);</span>
<span class="n">cumvar</span> <span class="o">=</span> <span class="nb">cumsum</span><span class="p">(</span><span class="n">eigvalue</span><span class="p">);</span> <span class="p">//</span><span class="n">cumulative</span> <span class="nb">sum</span> <span class="n">n</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)/</span><span class="mi">2</span>
<span class="n">cumvarpercent</span> <span class="o">=</span> <span class="n">cumvar</span><span class="p">/</span><span class="n">cumvar</span><span class="p">(</span><span class="k">end</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">;</span></code></pre></figure>

<h3 id="dimensionality-reduction">Dimensionality reduction</h3>
<p>Various researchers take statistics such as mean variance IQR, etc., to reduce the feature dimension. Some researchers model it using multivariate regression and some fit it to a Gaussian mixture model. Here we are taking the mean and upper diagonal variance of 13*n MFCC coefficients. The result is a feature vector of size 104.</p>

<figure class="highlight"><pre><code class="language-matlab" data-lang="matlab"> <span class="c1">%Reducing Feature Dimeansion</span>
 <span class="n">mf</span> <span class="o">=</span> <span class="nb">mean</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span> <span class="c1">%row mean</span>
 <span class="n">cf</span> <span class="o">=</span> <span class="nb">cov</span><span class="p">(</span><span class="n">mm</span><span class="o">'</span><span class="p">);</span> <span class="c1">% covariance</span>
 <span class="n">ff</span> <span class="o">=</span> <span class="n">mf</span><span class="p">;</span>
    <span class="k">for</span> <span class="nb">i</span><span class="o">=</span><span class="mi">0</span><span class="p">:(</span><span class="nb">size</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
     <span class="n">ff</span> <span class="o">=</span> <span class="p">[</span><span class="n">ff</span><span class="p">;</span><span class="nb">diag</span><span class="p">(</span><span class="n">cf</span><span class="p">,</span><span class="nb">i</span><span class="p">)];</span> <span class="c1">%use diagonals </span>
    <span class="k">end</span>
 <span class="n">t</span><span class="p">(:,</span><span class="k">end</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">ff</span><span class="p">(:,</span><span class="mi">1</span><span class="p">);</span></code></pre></figure>

<h3 id="classification">Classification</h3>
<p>#### K-nearest neighbors (KNN)
Principle is that the data instance of the same class should be closer in the feature space.
For a given data point x of unknown class, we can compute the distance between x and all
the data points in the training data and assign the class determined by k nearest points of x.</p>

<figure class="highlight"><pre><code class="language-matlab" data-lang="matlab"><span class="n">Suppose</span> <span class="n">we</span> <span class="n">are</span> <span class="n">given</span> <span class="n">training</span> <span class="n">dataset</span> <span class="n">of</span> <span class="n">n</span> <span class="n">points</span><span class="o">.</span>
<span class="p">{(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">),(</span><span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">)</span><span class="err">…</span><span class="p">(</span><span class="n">xn</span><span class="p">,</span><span class="n">yn</span><span class="p">)}</span>
    <span class="n">Where</span> <span class="p">(</span><span class="n">xi</span><span class="p">,</span><span class="n">yi</span><span class="p">)</span> <span class="n">represents</span> <span class="n">data</span> <span class="n">pair</span> <span class="nb">i</span><span class="o">.</span>
<span class="n">xi</span><span class="o">-</span> <span class="n">feature</span> <span class="n">vector</span>
<span class="n">yi</span><span class="o">-</span> <span class="n">target</span> <span class="nb">class</span></code></pre></figure>

<p>For a new data point x the most likely class is determined by finding the distance from all training data points (Euclidian distance).  The output class will be the class which k nearest neighbors belongs to. K is a predefined integer (k=1, k=2, k=3.) 
#### Logistic Regression</p>

<p>Logistic Regression is one of the widely used classification algorithm. This algorithm is used in medical as well as business fields for analytics and classification. This model has the hypothesis function  <code class="highlighter-rouge">0 ≤h  (x) ≤ 1.</code> Where  <code class="highlighter-rouge">hθ(x) = 11 + e-θTx  </code>called as Sigmoid or Logistic Function. For binary class classification<code class="highlighter-rouge"> y ∈{0, 1}</code>. The output of this classifier will be a probability of the given input belonging to class 1. If<code class="highlighter-rouge"> hθ(x) </code>outputs 0.7 it means that the given input has 70% chance of belonging to class 1.  Since we have 10 genre classes ` y ∈{0, 1 .. 9} `we used one-vs-all method for classification.</p>

<h2 id="python-package-mysvm">Python package <em>mysvm</em></h2>
<p>We developed a python package called <code class="highlighter-rouge">mysvm</code> which contains three modules: <em>features, svm, acc</em>. These are used by the web application in feature extraction and finding genre. This package also contains many other functions to do complicated feature extraction and classification.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>├── acc.py
├── data
│   ├── classifier_10class.pkl
│   ├── classifier_10class_prob.pkl
│   ├── cmpr.pkl
│   └── Xall.npy
├── feature.py
├── __init__.py
├── svm.py
</code></pre>
</div>

<h3 id="feature"><em>feature</em></h3>

<p>This module is used to extract MFCC features from a given file. It contains the following functions.
* <strong><em>extract (file):</em></strong> 
Extract features from a given file. Files in other formats are converted to .wav format. Returns numpy array.
* <strong><em>extract_all (audio_dir):</em></strong> 
Extracts features from all files in a directory. 
* <strong><em>extract_ratio (train_ratio, test_ratio, audio_dir) :</em></strong> 
Extract features from all files in a directory in a ratio. Returns two numpy arrays.
* <strong><em>geny(n):</em></strong> 
Generates <code class="highlighter-rouge">Y</code> values for <code class="highlighter-rouge">n</code> classes. Returns numpy array.
* <strong><em>gen_suby(sub, n):</em></strong>
Generates <code class="highlighter-rouge">Y</code> values for a subset of classes. Returns numpy array.
* <strong><em>gen_labels( ):</em></strong>
Returns a list of all genre labels.
* <strong><em>flattern( x) :</em></strong>
Flatterns a numpy array.</p>

<h3 id="svm"><em>svm</em></h3>

<p>A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. This module contains various functions for classification using support vector machines.</p>

<ul>
  <li>
    <p><strong><em>poly(X,Y):</em></strong> 
Trains a poly kernel SVM by fitting X, Y dataset. Returns a trained poly kernel SVM classifier.</p>
  </li>
  <li>
    <p><strong><em>fit ( training_percentage, fold):</em></strong> 
Randomly choose songs from the dataset, and train the classifier. Accepts parameter: <code class="highlighter-rouge">train_percentage, fold</code>; Returns trained classifier.</p>
  </li>
  <li>
    <p><strong><em>getprob (filename):</em></strong>
Find the probabilities for a song belongs to each genre. Returns a dictionary mapping genre names to probability and a list of top 3 genres which is having probability of more than 0.15.</p>
  </li>
  <li>
    <p><strong><em>random_cross_validation (train_percentage,fold):</em></strong>
Randomly cross validate with training percentage and fold. Accepts parameter: <code class="highlighter-rouge">train_percentage, fold</code>;</p>
  </li>
  <li>
    <p><strong><em>findsubclass (class_count):</em></strong>
Returns all possible ways we can combine the classes. Accepts an integer as class count. Returns numpy array of all possible combination.</p>
  </li>
  <li>
    <p><strong><em>gen_sub_data (class_l):</em></strong>
Generate a subset of the dataset for the given list of classes. Returns numpy array.</p>
  </li>
  <li>
    <p><strong><em>fitsvm (Xall, Yall, class_l, train_percentage, fold):</em></strong>
Fits a poly kernel svm and returns the accuracy. Accepts parameter: <code class="highlighter-rouge">train_percentage; fold</code>;  Returns: classifier, Accuracy.</p>
  </li>
  <li>
    <p><strong><em>best_combinations (class_l, train_percentage, fold):</em></strong>
Finds all possible combination of classes and the accuracy for the given number of classes Accepts: Training percentage, and number of folds Returns: A List of best combination possible for given the class count.</p>
  </li>
  <li>
    <p><strong><em>getgenre (filename):</em></strong>
Accepts a filename and returns a genre label for a given file.</p>
  </li>
  <li>
    <p><strong><em>getgenreMulti (filename):</em></strong>
Accepts a filename and returns top three genre labels based on the probability.</p>
  </li>
</ul>

<h3 id="acc"><em>acc</em></h3>
<p>Module for finding the accuracy.
* <strong><em>get ( res, test ) :</em></strong><br />
Compares two arrays and returns the accuracy of their match.</p>

<h1 id="results">Results</h1>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Classifier</th>
      <th style="text-align: center">Training Accuracy</th>
      <th style="text-align: center">Testing Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">K-Nearest Neighbors</td>
      <td style="text-align: center"> </td>
      <td style="text-align: center">53%</td>
    </tr>
    <tr>
      <td style="text-align: center">Logistic Regression</td>
      <td style="text-align: center">75.778%</td>
      <td style="text-align: center">54%</td>
    </tr>
    <tr>
      <td style="text-align: center">SVM Linear Kernel</td>
      <td style="text-align: center">99%</td>
      <td style="text-align: center">52%</td>
    </tr>
    <tr>
      <td style="text-align: center">SVM RBF Kernel</td>
      <td style="text-align: center">99%</td>
      <td style="text-align: center">12%</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>SVM Poly Kernel</strong></td>
      <td style="text-align: center"><strong>99%</strong></td>
      <td style="text-align: center"><strong>64%</strong></td>
    </tr>
  </tbody>
</table>

<p>** 6 genre classes we are getting an accuracy of 85%**</p>

<h2 id="conclusion">Conclusion</h2>

<p>We have tried various machine learning algorithms for this project. Our aim is to get maximum accuracy. We have found from our research that we can a get maximum accuracy of <code class="highlighter-rouge">65%</code> by using <code class="highlighter-rouge">poly kernel SVM</code> for 10 genre classes. We have also tried to find the best combination of genre classes which will result in maximum accuracy. If we choose 6 genre classes we were able to get an accuracy of <code class="highlighter-rouge">85%</code>. We chose these labels for the Web Application [classical, hip-hop, jazz, metal, pop and rock]
For some songs we can say that it has feature of multiple genres. So we have also tried to get multiple label outputs based on the probability.</p>

<h1 id="license">License</h1>
<p><a href="https://github.com/indrajithi/mgc-django">Source</a> GPL v2.0, MIT. See LICENSE.txt</p>

        
      </div><!-- /.entry-content -->
    </div><!-- /.entry-wrapper -->
    <nav class="pagination" role="navigation">
      
        <a href="http://localhost:4000/blog/music-visualizer-in-c-using-opengl-part-4/" class="btn" title="Music Visualizer in C++ Using OpenGL Part 4">Previous</a>
      
      
    </nav><!-- /.pagination -->
  </article>
</div><!-- /#main -->



<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    

<span><img src="https://mirrors.creativecommons.org/presskit/icons/cc.large.png" style="width:20px;height:20px;"> 2018  Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll.</a> </span>
<div class="social-icons">
	
	<a href="https://facebook.com/anandnautiyal123" title="Anand Nautiyal on Facebook" target="_blank"><i class="fa fa-facebook-square fa-2x"></i></a>
	
	<a href="https://linkedin.com/in/anand-nautiyal-76227b7/" title="Anand Nautiyal on LinkedIn" target="_blank"><i class="fa fa-linkedin-square fa-2x"></i></a>
	
	<a href="https://instagram.com/anand_23" title="Anand Nautiyal on Instagram" target="_blank"><i class="fa fa-instagram fa-2x"></i></a>
	
	<a href="https://github.com/AnandNautiyal23" title="Anand Nautiyal on Github" target="_blank"><i class="fa fa-github-square fa-2x"></i></a>
	
  
	
  <a href="http://localhost:4000/feed.xml" title="Atom/RSS feed"><i class="fa fa-rss-square fa-2x"></i></a>
</div><!-- /.social-icons -->

  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = 'http://localhost:4000';
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>




</body>
</html>
